{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.num_envs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_envs` for environment variables or `env.get_wrapper_attr('num_envs')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/markus/.local/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward_space` for environment variables or `env.get_wrapper_attr('reward_space')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "from torchrl.envs import GymEnv\n",
    "\n",
    "env = GymEnv(\"Pendulum-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "reset = env.reset()\n",
    "print(reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "reset_with_action = env.rand_action(reset)\n",
    "print(reset_with_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "stepped_data = env.step(reset_with_action)\n",
    "print(stepped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1264, -0.9920, -1.6453])\n",
      "tensor([ 0.2074, -0.9782, -0.9377])\n",
      "tensor([ 0.2074, -0.9782, -0.9377])\n"
     ]
    }
   ],
   "source": [
    "print(stepped_data[\"next\"][\"observation\"])\n",
    "print(stepped_data[\"observation\"])\n",
    "print(reset_with_action[\"observation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "from torchrl.envs import step_mdp\n",
    "\n",
    "data = step_mdp(stepped_data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1264, -0.9920, -1.6453])\n"
     ]
    }
   ],
   "source": [
    "print(data[\"observation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([10]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([10]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "rollout = env.rollout(max_steps=10)\n",
    "print(rollout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5032],\n",
      "        [-0.2687],\n",
      "        [-0.7964],\n",
      "        [ 0.2483],\n",
      "        [-0.5507],\n",
      "        [ 1.6441],\n",
      "        [ 0.4023],\n",
      "        [-1.9425],\n",
      "        [-1.7118],\n",
      "        [ 0.1959]])\n",
      "tensor([[ 0.0532, -0.9986, -0.9143],\n",
      "        [-0.0412, -0.9991, -1.8888],\n",
      "        [-0.1743, -0.9847, -2.6784],\n",
      "        [-0.3448, -0.9387, -3.5364],\n",
      "        [-0.5330, -0.8461, -4.2032],\n",
      "        [-0.7230, -0.6908, -4.9204],\n",
      "        [-0.8761, -0.4821, -5.1919],\n",
      "        [-0.9740, -0.2264, -5.4931],\n",
      "        [-0.9976,  0.0693, -5.9543],\n",
      "        [-0.9297,  0.3684, -6.1591]])\n",
      "tensor([[-0.0412, -0.9991, -1.8888],\n",
      "        [-0.1743, -0.9847, -2.6784],\n",
      "        [-0.3448, -0.9387, -3.5364],\n",
      "        [-0.5330, -0.8461, -4.2032],\n",
      "        [-0.7230, -0.6908, -4.9204],\n",
      "        [-0.8761, -0.4821, -5.1919],\n",
      "        [-0.9740, -0.2264, -5.4931],\n",
      "        [-0.9976,  0.0693, -5.9543],\n",
      "        [-0.9297,  0.3684, -6.1591],\n",
      "        [-0.7839,  0.6209, -5.8534]])\n"
     ]
    }
   ],
   "source": [
    "print(rollout[\"action\"])\n",
    "print(rollout[\"observation\"])\n",
    "print(rollout[\"next\"][\"observation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0412, -0.9991, -1.8888],\n",
      "        [-0.1743, -0.9847, -2.6784],\n",
      "        [-0.3448, -0.9387, -3.5364],\n",
      "        [-0.5330, -0.8461, -4.2032],\n",
      "        [-0.7230, -0.6908, -4.9204],\n",
      "        [-0.8761, -0.4821, -5.1919],\n",
      "        [-0.9740, -0.2264, -5.4931],\n",
      "        [-0.9976,  0.0693, -5.9543],\n",
      "        [-0.9297,  0.3684, -6.1591],\n",
      "        [-0.7839,  0.6209, -5.8534]])\n"
     ]
    }
   ],
   "source": [
    "data = step_mdp(rollout)\n",
    "print(data[\"observation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                step_count: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([10]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        step_count: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([10]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "from torchrl.envs import StepCounter, TransformedEnv\n",
    "\n",
    "transformed_env = TransformedEnv(env, StepCounter(max_steps=10))\n",
    "rollout = transformed_env.rollout(max_steps=100)\n",
    "print(rollout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.num_envs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_envs` for environment variables or `env.get_wrapper_attr('num_envs')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/markus/.local/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward_space` for environment variables or `env.get_wrapper_attr('reward_space')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/markus/.local/lib/python3.10/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from tensordict.nn import TensorDictModule\n",
    "from torchrl.envs import GymEnv\n",
    "\n",
    "env = GymEnv(\"Pendulum-v1\")\n",
    "module = torch.nn.LazyLinear(out_features=env.action_spec.shape[-1])\n",
    "policy = TensorDictModule(\n",
    "    module,\n",
    "    in_keys=[\"observation\"],\n",
    "    out_keys=[\"action\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([10]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([10]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "rollout = env.rollout(max_steps=10, policy=policy)\n",
    "print(rollout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        loc: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([10]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        sample_log_prob: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        scale: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([10]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "from tensordict.nn.distributions import NormalParamExtractor\n",
    "from torch.distributions import Normal\n",
    "from torchrl.modules import ProbabilisticActor\n",
    "from torchrl.modules import MLP\n",
    "\n",
    "backbone = MLP(in_features=3, out_features=2)\n",
    "extractor = NormalParamExtractor()\n",
    "module = torch.nn.Sequential(backbone, extractor)\n",
    "td_module = TensorDictModule(module, in_keys=[\"observation\"], out_keys=[\"loc\", \"scale\"])\n",
    "policy = ProbabilisticActor(\n",
    "    td_module,\n",
    "    in_keys=[\"loc\", \"scale\"],\n",
    "    out_keys=[\"action\"],\n",
    "    distribution_class=Normal,\n",
    "    return_log_prob=True,\n",
    ")\n",
    "\n",
    "rollout = env.rollout(max_steps=10, policy=policy)\n",
    "print(rollout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.envs.utils import ExplorationType, set_exploration_type\n",
    "\n",
    "with set_exploration_type(ExplorationType.MEAN):\n",
    "    # takes the mean as action\n",
    "    rollout = env.rollout(max_steps=10, policy=policy)\n",
    "with set_exploration_type(ExplorationType.RANDOM):\n",
    "    # Samples actions according to the dist\n",
    "    rollout = env.rollout(max_steps=10, policy=policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensordict.nn import TensorDictSequential\n",
    "from torchrl.modules import EGreedyModule\n",
    "from torchrl.modules import Actor\n",
    "\n",
    "policy = Actor(MLP(3, 1, num_cells=[32, 64]))\n",
    "exploration_module = EGreedyModule(\n",
    "    spec=env.action_spec, annealing_num_steps=1000, eps_init=0.5\n",
    ")\n",
    "exploration_policy = TensorDictSequential(policy, exploration_module)\n",
    "\n",
    "with set_exploration_type(ExplorationType.MEAN):\n",
    "    # Turns off exploration\n",
    "    rollout = env.rollout(max_steps=10, policy=exploration_policy)\n",
    "with set_exploration_type(ExplorationType.RANDOM):\n",
    "    # Turns on exploration\n",
    "    rollout = env.rollout(max_steps=10, policy=exploration_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotDiscreteTensorSpec(\n",
      "    shape=torch.Size([2]),\n",
      "    space=DiscreteBox(n=2),\n",
      "    device=cpu,\n",
      "    dtype=torch.int64,\n",
      "    domain=discrete)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.num_envs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_envs` for environment variables or `env.get_wrapper_attr('num_envs')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/markus/.local/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward_space` for environment variables or `env.get_wrapper_attr('reward_space')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = GymEnv(\"CartPole-v1\")\n",
    "print(env.action_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.10/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "num_actions = 2\n",
    "value_net = TensorDictModule(\n",
    "    MLP(out_features=num_actions, num_cells=[32, 32]),\n",
    "    in_keys=[\"observation\"],\n",
    "    out_keys=[\"action_value\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.modules import QValueModule\n",
    "\n",
    "policy = TensorDictSequential(\n",
    "    value_net,  # writes action values in our tensordict\n",
    "    QValueModule(\n",
    "        action_space=env.action_spec\n",
    "    ),  # Reads the \"action_value\" entry by default\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([3, 2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "        action_value: Tensor(shape=torch.Size([3, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        chosen_action_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([3]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([3]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "rollout = env.rollout(max_steps=3, policy=policy)\n",
    "print(rollout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "OneHotDiscreteTensorSpec(\n",
      "    shape=torch.Size([2]),\n",
      "    space=DiscreteBox(n=2),\n",
      "    device=cpu,\n",
      "    dtype=torch.int64,\n",
      "    domain=discrete)\n"
     ]
    }
   ],
   "source": [
    "print(rollout[\"action\"])\n",
    "print(env.action_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.num_envs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_envs` for environment variables or `env.get_wrapper_attr('num_envs')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/markus/.local/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward_space` for environment variables or `env.get_wrapper_attr('reward_space')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "from torchrl.envs import GymEnv\n",
    "\n",
    "env = GymEnv(\"Pendulum-v1\")\n",
    "\n",
    "from torchrl.modules import Actor, MLP, ValueOperator\n",
    "from torchrl.objectives import DDPGLoss\n",
    "\n",
    "n_obs = env.observation_spec[\"observation\"].shape[-1]\n",
    "n_act = env.action_spec.shape[-1]\n",
    "actor = Actor(MLP(in_features=n_obs, out_features=n_act, num_cells=[32, 32]))\n",
    "value_net = ValueOperator(\n",
    "    MLP(in_features=n_obs + n_act, out_features=1, num_cells=[32, 32]),\n",
    "    in_keys=[\"observation\", \"action\"],\n",
    ")\n",
    "\n",
    "ddpg_loss = DDPGLoss(actor_network=actor, value_network=value_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        loss_actor: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        loss_value: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        pred_value: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        pred_value_max: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        target_value: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        target_value_max: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        td_error: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.10/site-packages/torchrl/objectives/common.py:29: UserWarning: No target network updater has been associated with this loss module, but target parameters have been found. While this is supported, it is expected that the target network updates will be manually performed. You can deactivate this warning by turning the RL_WARNINGS env variable to False.\n",
      "  warnings.warn(\n",
      "/home/markus/.local/lib/python3.10/site-packages/torchrl/objectives/common.py:324: UserWarning: No target network updater has been associated with this loss module, but target parameters have been found. While this is supported, it is expected that the target network updates will be manually performed. You can deactivate this warning by turning the RL_WARNINGS env variable to False.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rollout = env.rollout(max_steps=100, policy=actor)\n",
    "loss_vals = ddpg_loss(rollout)\n",
    "print(loss_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "total_loss = 0\n",
    "for key, val in loss_vals.items():\n",
    "    if key.startswith(\"loss_\"):\n",
    "        total_loss += val\n",
    "optim = Adam(ddpg_loss.parameters())\n",
    "total_loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.step()\n",
    "optim.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.num_envs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_envs` for environment variables or `env.get_wrapper_attr('num_envs')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/markus/.local/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward_space` for environment variables or `env.get_wrapper_attr('reward_space')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.envs import GymEnv\n",
    "from torchrl.envs.utils import RandomPolicy\n",
    "\n",
    "env = GymEnv(\"CartPole-v1\")\n",
    "env.set_seed(0)\n",
    "\n",
    "policy = RandomPolicy(env.action_spec)\n",
    "collector = SyncDataCollector(env, policy, frames_per_batch=200, total_frames=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([200, 2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "        collector: TensorDict(\n",
      "            fields={\n",
      "                traj_ids: Tensor(shape=torch.Size([200]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
      "            batch_size=torch.Size([200]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([200, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([200]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([200, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([200]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "for data in collector:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([30, 2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "        collector: TensorDict(\n",
      "            fields={\n",
      "                traj_ids: Tensor(shape=torch.Size([30]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
      "            batch_size=torch.Size([30]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([30, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([30]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([30, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([30]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "from torchrl.data.replay_buffers import LazyMemmapStorage, ReplayBuffer\n",
    "\n",
    "buffer = ReplayBuffer(storage=LazyMemmapStorage(max_size=1000))\n",
    "indices = buffer.extend(data)\n",
    "assert len(buffer) == collector.frames_per_batch\n",
    "sample = buffer.sample(batch_size=30)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.num_envs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_envs` for environment variables or `env.get_wrapper_attr('num_envs')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([3, 2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                pixels: Tensor(shape=torch.Size([3, 400, 600, 3]), device=cpu, dtype=torch.uint8, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([3]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        pixels: Tensor(shape=torch.Size([3, 400, 600, 3]), device=cpu, dtype=torch.uint8, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([3]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward_space` for environment variables or `env.get_wrapper_attr('reward_space')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "from torchrl.record import CSVLogger\n",
    "\n",
    "logger = CSVLogger(exp_name=\"my_exp\")\n",
    "logger.log_scalar(\"my_scalar\", 0.4)\n",
    "from torchrl.envs import GymEnv\n",
    "\n",
    "env = GymEnv(\"CartPole-v1\", from_pixels=True, pixels_only=False)\n",
    "\n",
    "print(env.rollout(max_steps=3))\n",
    "\n",
    "from torchrl.envs import TransformedEnv\n",
    "from torchrl.record import VideoRecorder\n",
    "\n",
    "recorder = VideoRecorder(logger, tag=\"my_video\")\n",
    "record_env = TransformedEnv(env, recorder)\n",
    "rollout = record_env.rollout(max_steps=3)\n",
    "# Uncomment this line to save the video on disk:\n",
    "# recorder.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.num_envs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_envs` for environment variables or `env.get_wrapper_attr('num_envs')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/markus/.local/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward_space` for environment variables or `env.get_wrapper_attr('reward_space')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import time\n",
    "\n",
    "from torchrl.envs import GymEnv, StepCounter, TransformedEnv\n",
    "\n",
    "env = TransformedEnv(GymEnv(\"CartPole-v1\"), StepCounter())\n",
    "env.set_seed(0)\n",
    "\n",
    "from tensordict.nn import TensorDictModule as Mod, TensorDictSequential as Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.10/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/home/markus/.local/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.num_envs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_envs` for environment variables or `env.get_wrapper_attr('num_envs')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/markus/.local/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward_space` for environment variables or `env.get_wrapper_attr('reward_space')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "2024-04-17 21:03:41,913 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
      "2024-04-17 21:03:41,925 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
      "2024-04-17 21:03:41,941 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
      "2024-04-17 21:03:41,970 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
      "2024-04-17 21:03:41,998 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
      "2024-04-17 21:03:42,015 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
      "2024-04-17 21:03:42,032 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
      "2024-04-17 21:03:42,046 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
      "2024-04-17 21:03:42,067 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
      "2024-04-17 21:03:42,081 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
      "2024-04-17 21:03:42,332 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
      "2024-04-17 21:03:42,348 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
      "2024-04-17 21:03:42,368 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
      "2024-04-17 21:03:42,388 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
      "2024-04-17 21:03:42,430 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
      "2024-04-17 21:03:42,509 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
      "2024-04-17 21:03:42,531 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
      "2024-04-17 21:03:42,548 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
      "2024-04-17 21:03:42,598 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
      "2024-04-17 21:03:42,612 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
      "2024-04-17 21:03:42,839 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
      "2024-04-17 21:03:42,855 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
      "2024-04-17 21:03:42,882 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
      "2024-04-17 21:03:42,904 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
      "2024-04-17 21:03:42,935 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
      "2024-04-17 21:03:42,988 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
      "2024-04-17 21:03:43,012 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
      "2024-04-17 21:03:43,048 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
      "2024-04-17 21:03:43,069 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
      "2024-04-17 21:03:43,107 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
      "2024-04-17 21:03:43,343 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
      "2024-04-17 21:03:43,357 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
      "2024-04-17 21:03:43,386 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
      "2024-04-17 21:03:43,403 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
      "2024-04-17 21:03:43,422 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
      "2024-04-17 21:03:43,440 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
      "2024-04-17 21:03:43,467 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
      "2024-04-17 21:03:43,492 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
      "2024-04-17 21:03:43,509 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
      "2024-04-17 21:03:43,534 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
      "2024-04-17 21:03:43,734 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
      "2024-04-17 21:03:43,750 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
      "2024-04-17 21:03:43,784 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
      "2024-04-17 21:03:43,801 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
      "2024-04-17 21:03:43,824 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
      "2024-04-17 21:03:43,845 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
      "2024-04-17 21:03:43,863 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
      "2024-04-17 21:03:43,881 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
      "2024-04-17 21:03:43,899 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
      "2024-04-17 21:03:43,921 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
      "2024-04-17 21:03:44,104 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
      "2024-04-17 21:03:44,120 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
      "2024-04-17 21:03:44,137 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
      "2024-04-17 21:03:44,162 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
      "2024-04-17 21:03:44,190 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
      "2024-04-17 21:03:44,214 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
      "2024-04-17 21:03:44,241 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
      "2024-04-17 21:03:44,264 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
      "2024-04-17 21:03:44,281 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
      "2024-04-17 21:03:44,303 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
      "2024-04-17 21:03:44,541 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
      "2024-04-17 21:03:44,560 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
      "2024-04-17 21:03:44,579 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
      "2024-04-17 21:03:44,603 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
      "2024-04-17 21:03:44,623 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
      "2024-04-17 21:03:44,691 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
      "2024-04-17 21:03:44,741 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
      "2024-04-17 21:03:44,761 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
      "2024-04-17 21:03:44,779 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
      "2024-04-17 21:03:44,827 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
      "2024-04-17 21:03:45,080 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
      "2024-04-17 21:03:45,095 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
      "2024-04-17 21:03:45,115 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
      "2024-04-17 21:03:45,147 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
      "2024-04-17 21:03:45,186 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
      "2024-04-17 21:03:45,241 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
      "2024-04-17 21:03:45,259 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
      "2024-04-17 21:03:45,285 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
      "2024-04-17 21:03:45,307 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
      "2024-04-17 21:03:45,322 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
      "2024-04-17 21:03:45,530 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
      "2024-04-17 21:03:45,546 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
      "2024-04-17 21:03:45,566 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
      "2024-04-17 21:03:45,588 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
      "2024-04-17 21:03:45,615 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
      "2024-04-17 21:03:45,630 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
      "2024-04-17 21:03:45,649 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
      "2024-04-17 21:03:45,665 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
      "2024-04-17 21:03:45,682 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
      "2024-04-17 21:03:45,697 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
      "2024-04-17 21:03:46,106 [torchrl][INFO] Max num steps: 103, rb length 6200\n",
      "2024-04-17 21:03:46,122 [torchrl][INFO] Max num steps: 103, rb length 6200\n",
      "2024-04-17 21:03:46,135 [torchrl][INFO] Max num steps: 103, rb length 6200\n",
      "2024-04-17 21:03:46,148 [torchrl][INFO] Max num steps: 103, rb length 6200\n",
      "2024-04-17 21:03:46,166 [torchrl][INFO] Max num steps: 103, rb length 6200\n",
      "2024-04-17 21:03:46,182 [torchrl][INFO] Max num steps: 103, rb length 6200\n",
      "2024-04-17 21:03:46,196 [torchrl][INFO] Max num steps: 103, rb length 6200\n",
      "2024-04-17 21:03:46,218 [torchrl][INFO] Max num steps: 103, rb length 6200\n",
      "2024-04-17 21:03:46,235 [torchrl][INFO] Max num steps: 103, rb length 6200\n",
      "2024-04-17 21:03:46,249 [torchrl][INFO] Max num steps: 103, rb length 6200\n",
      "2024-04-17 21:03:46,424 [torchrl][INFO] Max num steps: 174, rb length 6300\n",
      "2024-04-17 21:03:46,441 [torchrl][INFO] Max num steps: 174, rb length 6300\n",
      "2024-04-17 21:03:46,469 [torchrl][INFO] Max num steps: 174, rb length 6300\n",
      "2024-04-17 21:03:46,489 [torchrl][INFO] Max num steps: 174, rb length 6300\n",
      "2024-04-17 21:03:46,507 [torchrl][INFO] Max num steps: 174, rb length 6300\n",
      "2024-04-17 21:03:46,528 [torchrl][INFO] Max num steps: 174, rb length 6300\n",
      "2024-04-17 21:03:46,548 [torchrl][INFO] Max num steps: 174, rb length 6300\n",
      "2024-04-17 21:03:46,564 [torchrl][INFO] Max num steps: 174, rb length 6300\n",
      "2024-04-17 21:03:46,581 [torchrl][INFO] Max num steps: 174, rb length 6300\n",
      "2024-04-17 21:03:46,597 [torchrl][INFO] Max num steps: 174, rb length 6300\n",
      "2024-04-17 21:03:46,777 [torchrl][INFO] Max num steps: 174, rb length 6400\n",
      "2024-04-17 21:03:46,789 [torchrl][INFO] Max num steps: 174, rb length 6400\n",
      "2024-04-17 21:03:46,805 [torchrl][INFO] Max num steps: 174, rb length 6400\n",
      "2024-04-17 21:03:46,822 [torchrl][INFO] Max num steps: 174, rb length 6400\n",
      "2024-04-17 21:03:46,837 [torchrl][INFO] Max num steps: 174, rb length 6400\n",
      "2024-04-17 21:03:46,858 [torchrl][INFO] Max num steps: 174, rb length 6400\n",
      "2024-04-17 21:03:46,880 [torchrl][INFO] Max num steps: 174, rb length 6400\n",
      "2024-04-17 21:03:46,904 [torchrl][INFO] Max num steps: 174, rb length 6400\n",
      "2024-04-17 21:03:46,921 [torchrl][INFO] Max num steps: 174, rb length 6400\n",
      "2024-04-17 21:03:46,936 [torchrl][INFO] Max num steps: 174, rb length 6400\n",
      "2024-04-17 21:03:47,091 [torchrl][INFO] Max num steps: 174, rb length 6500\n",
      "2024-04-17 21:03:47,103 [torchrl][INFO] Max num steps: 174, rb length 6500\n",
      "2024-04-17 21:03:47,118 [torchrl][INFO] Max num steps: 174, rb length 6500\n",
      "2024-04-17 21:03:47,131 [torchrl][INFO] Max num steps: 174, rb length 6500\n",
      "2024-04-17 21:03:47,144 [torchrl][INFO] Max num steps: 174, rb length 6500\n",
      "2024-04-17 21:03:47,160 [torchrl][INFO] Max num steps: 174, rb length 6500\n",
      "2024-04-17 21:03:47,175 [torchrl][INFO] Max num steps: 174, rb length 6500\n",
      "2024-04-17 21:03:47,191 [torchrl][INFO] Max num steps: 174, rb length 6500\n",
      "2024-04-17 21:03:47,205 [torchrl][INFO] Max num steps: 174, rb length 6500\n",
      "2024-04-17 21:03:47,219 [torchrl][INFO] Max num steps: 174, rb length 6500\n",
      "2024-04-17 21:03:47,396 [torchrl][INFO] Max num steps: 174, rb length 6600\n",
      "2024-04-17 21:03:47,411 [torchrl][INFO] Max num steps: 174, rb length 6600\n",
      "2024-04-17 21:03:47,425 [torchrl][INFO] Max num steps: 174, rb length 6600\n",
      "2024-04-17 21:03:47,445 [torchrl][INFO] Max num steps: 174, rb length 6600\n",
      "2024-04-17 21:03:47,463 [torchrl][INFO] Max num steps: 174, rb length 6600\n",
      "2024-04-17 21:03:47,476 [torchrl][INFO] Max num steps: 174, rb length 6600\n",
      "2024-04-17 21:03:47,495 [torchrl][INFO] Max num steps: 174, rb length 6600\n",
      "2024-04-17 21:03:47,511 [torchrl][INFO] Max num steps: 174, rb length 6600\n",
      "2024-04-17 21:03:47,537 [torchrl][INFO] Max num steps: 174, rb length 6600\n",
      "2024-04-17 21:03:47,555 [torchrl][INFO] Max num steps: 174, rb length 6600\n",
      "2024-04-17 21:03:47,704 [torchrl][INFO] Max num steps: 174, rb length 6700\n",
      "2024-04-17 21:03:47,716 [torchrl][INFO] Max num steps: 174, rb length 6700\n",
      "2024-04-17 21:03:47,732 [torchrl][INFO] Max num steps: 174, rb length 6700\n",
      "2024-04-17 21:03:47,744 [torchrl][INFO] Max num steps: 174, rb length 6700\n",
      "2024-04-17 21:03:47,759 [torchrl][INFO] Max num steps: 174, rb length 6700\n",
      "2024-04-17 21:03:47,776 [torchrl][INFO] Max num steps: 174, rb length 6700\n",
      "2024-04-17 21:03:47,790 [torchrl][INFO] Max num steps: 174, rb length 6700\n",
      "2024-04-17 21:03:47,803 [torchrl][INFO] Max num steps: 174, rb length 6700\n",
      "2024-04-17 21:03:47,816 [torchrl][INFO] Max num steps: 174, rb length 6700\n",
      "2024-04-17 21:03:47,829 [torchrl][INFO] Max num steps: 174, rb length 6700\n",
      "2024-04-17 21:03:47,991 [torchrl][INFO] Max num steps: 174, rb length 6800\n",
      "2024-04-17 21:03:48,003 [torchrl][INFO] Max num steps: 174, rb length 6800\n",
      "2024-04-17 21:03:48,016 [torchrl][INFO] Max num steps: 174, rb length 6800\n",
      "2024-04-17 21:03:48,028 [torchrl][INFO] Max num steps: 174, rb length 6800\n",
      "2024-04-17 21:03:48,045 [torchrl][INFO] Max num steps: 174, rb length 6800\n",
      "2024-04-17 21:03:48,058 [torchrl][INFO] Max num steps: 174, rb length 6800\n",
      "2024-04-17 21:03:48,075 [torchrl][INFO] Max num steps: 174, rb length 6800\n",
      "2024-04-17 21:03:48,091 [torchrl][INFO] Max num steps: 174, rb length 6800\n",
      "2024-04-17 21:03:48,105 [torchrl][INFO] Max num steps: 174, rb length 6800\n",
      "2024-04-17 21:03:48,123 [torchrl][INFO] Max num steps: 174, rb length 6800\n",
      "2024-04-17 21:03:48,267 [torchrl][INFO] Max num steps: 174, rb length 6900\n",
      "2024-04-17 21:03:48,280 [torchrl][INFO] Max num steps: 174, rb length 6900\n",
      "2024-04-17 21:03:48,292 [torchrl][INFO] Max num steps: 174, rb length 6900\n",
      "2024-04-17 21:03:48,311 [torchrl][INFO] Max num steps: 174, rb length 6900\n",
      "2024-04-17 21:03:48,324 [torchrl][INFO] Max num steps: 174, rb length 6900\n",
      "2024-04-17 21:03:48,340 [torchrl][INFO] Max num steps: 174, rb length 6900\n",
      "2024-04-17 21:03:48,354 [torchrl][INFO] Max num steps: 174, rb length 6900\n",
      "2024-04-17 21:03:48,371 [torchrl][INFO] Max num steps: 174, rb length 6900\n",
      "2024-04-17 21:03:48,383 [torchrl][INFO] Max num steps: 174, rb length 6900\n",
      "2024-04-17 21:03:48,400 [torchrl][INFO] Max num steps: 174, rb length 6900\n",
      "2024-04-17 21:03:48,633 [torchrl][INFO] Max num steps: 174, rb length 7000\n",
      "2024-04-17 21:03:48,649 [torchrl][INFO] Max num steps: 174, rb length 7000\n",
      "2024-04-17 21:03:48,678 [torchrl][INFO] Max num steps: 174, rb length 7000\n",
      "2024-04-17 21:03:48,692 [torchrl][INFO] Max num steps: 174, rb length 7000\n",
      "2024-04-17 21:03:48,722 [torchrl][INFO] Max num steps: 174, rb length 7000\n",
      "2024-04-17 21:03:48,735 [torchrl][INFO] Max num steps: 174, rb length 7000\n",
      "2024-04-17 21:03:48,748 [torchrl][INFO] Max num steps: 174, rb length 7000\n",
      "2024-04-17 21:03:48,762 [torchrl][INFO] Max num steps: 174, rb length 7000\n",
      "2024-04-17 21:03:48,776 [torchrl][INFO] Max num steps: 174, rb length 7000\n",
      "2024-04-17 21:03:48,790 [torchrl][INFO] Max num steps: 174, rb length 7000\n",
      "2024-04-17 21:03:49,173 [torchrl][INFO] Max num steps: 174, rb length 7200\n",
      "2024-04-17 21:03:49,185 [torchrl][INFO] Max num steps: 174, rb length 7200\n",
      "2024-04-17 21:03:49,201 [torchrl][INFO] Max num steps: 174, rb length 7200\n",
      "2024-04-17 21:03:49,213 [torchrl][INFO] Max num steps: 174, rb length 7200\n",
      "2024-04-17 21:03:49,225 [torchrl][INFO] Max num steps: 174, rb length 7200\n",
      "2024-04-17 21:03:49,242 [torchrl][INFO] Max num steps: 174, rb length 7200\n",
      "2024-04-17 21:03:49,256 [torchrl][INFO] Max num steps: 174, rb length 7200\n",
      "2024-04-17 21:03:49,272 [torchrl][INFO] Max num steps: 174, rb length 7200\n",
      "2024-04-17 21:03:49,289 [torchrl][INFO] Max num steps: 174, rb length 7200\n",
      "2024-04-17 21:03:49,316 [torchrl][INFO] Max num steps: 174, rb length 7200\n",
      "2024-04-17 21:03:49,468 [torchrl][INFO] Max num steps: 194, rb length 7300\n",
      "2024-04-17 21:03:49,484 [torchrl][INFO] Max num steps: 194, rb length 7300\n",
      "2024-04-17 21:03:49,500 [torchrl][INFO] Max num steps: 194, rb length 7300\n",
      "2024-04-17 21:03:49,519 [torchrl][INFO] Max num steps: 194, rb length 7300\n",
      "2024-04-17 21:03:49,540 [torchrl][INFO] Max num steps: 194, rb length 7300\n",
      "2024-04-17 21:03:49,556 [torchrl][INFO] Max num steps: 194, rb length 7300\n",
      "2024-04-17 21:03:49,571 [torchrl][INFO] Max num steps: 194, rb length 7300\n",
      "2024-04-17 21:03:49,585 [torchrl][INFO] Max num steps: 194, rb length 7300\n",
      "2024-04-17 21:03:49,596 [torchrl][INFO] Max num steps: 194, rb length 7300\n",
      "2024-04-17 21:03:49,610 [torchrl][INFO] Max num steps: 194, rb length 7300\n",
      "2024-04-17 21:03:49,814 [torchrl][INFO] Max num steps: 194, rb length 7400\n",
      "2024-04-17 21:03:49,829 [torchrl][INFO] Max num steps: 194, rb length 7400\n",
      "2024-04-17 21:03:49,846 [torchrl][INFO] Max num steps: 194, rb length 7400\n",
      "2024-04-17 21:03:49,870 [torchrl][INFO] Max num steps: 194, rb length 7400\n",
      "2024-04-17 21:03:49,886 [torchrl][INFO] Max num steps: 194, rb length 7400\n",
      "2024-04-17 21:03:49,910 [torchrl][INFO] Max num steps: 194, rb length 7400\n",
      "2024-04-17 21:03:49,953 [torchrl][INFO] Max num steps: 194, rb length 7400\n",
      "2024-04-17 21:03:49,970 [torchrl][INFO] Max num steps: 194, rb length 7400\n",
      "2024-04-17 21:03:49,995 [torchrl][INFO] Max num steps: 194, rb length 7400\n",
      "2024-04-17 21:03:50,011 [torchrl][INFO] Max num steps: 194, rb length 7400\n",
      "2024-04-17 21:03:50,210 [torchrl][INFO] Max num steps: 194, rb length 7500\n",
      "2024-04-17 21:03:50,223 [torchrl][INFO] Max num steps: 194, rb length 7500\n",
      "2024-04-17 21:03:50,248 [torchrl][INFO] Max num steps: 194, rb length 7500\n",
      "2024-04-17 21:03:50,266 [torchrl][INFO] Max num steps: 194, rb length 7500\n",
      "2024-04-17 21:03:50,285 [torchrl][INFO] Max num steps: 194, rb length 7500\n",
      "2024-04-17 21:03:50,303 [torchrl][INFO] Max num steps: 194, rb length 7500\n",
      "2024-04-17 21:03:50,317 [torchrl][INFO] Max num steps: 194, rb length 7500\n",
      "2024-04-17 21:03:50,331 [torchrl][INFO] Max num steps: 194, rb length 7500\n",
      "2024-04-17 21:03:50,345 [torchrl][INFO] Max num steps: 194, rb length 7500\n",
      "2024-04-17 21:03:50,362 [torchrl][INFO] Max num steps: 194, rb length 7500\n",
      "2024-04-17 21:03:50,541 [torchrl][INFO] Max num steps: 194, rb length 7600\n",
      "2024-04-17 21:03:50,556 [torchrl][INFO] Max num steps: 194, rb length 7600\n",
      "2024-04-17 21:03:50,574 [torchrl][INFO] Max num steps: 194, rb length 7600\n",
      "2024-04-17 21:03:50,588 [torchrl][INFO] Max num steps: 194, rb length 7600\n",
      "2024-04-17 21:03:50,603 [torchrl][INFO] Max num steps: 194, rb length 7600\n",
      "2024-04-17 21:03:50,620 [torchrl][INFO] Max num steps: 194, rb length 7600\n",
      "2024-04-17 21:03:50,634 [torchrl][INFO] Max num steps: 194, rb length 7600\n",
      "2024-04-17 21:03:50,647 [torchrl][INFO] Max num steps: 194, rb length 7600\n",
      "2024-04-17 21:03:50,661 [torchrl][INFO] Max num steps: 194, rb length 7600\n",
      "2024-04-17 21:03:50,673 [torchrl][INFO] Max num steps: 194, rb length 7600\n",
      "2024-04-17 21:03:50,814 [torchrl][INFO] Max num steps: 194, rb length 7700\n",
      "2024-04-17 21:03:50,824 [torchrl][INFO] Max num steps: 194, rb length 7700\n",
      "2024-04-17 21:03:50,845 [torchrl][INFO] Max num steps: 194, rb length 7700\n",
      "2024-04-17 21:03:50,858 [torchrl][INFO] Max num steps: 194, rb length 7700\n",
      "2024-04-17 21:03:50,873 [torchrl][INFO] Max num steps: 194, rb length 7700\n",
      "2024-04-17 21:03:50,889 [torchrl][INFO] Max num steps: 194, rb length 7700\n",
      "2024-04-17 21:03:50,902 [torchrl][INFO] Max num steps: 194, rb length 7700\n",
      "2024-04-17 21:03:50,918 [torchrl][INFO] Max num steps: 194, rb length 7700\n",
      "2024-04-17 21:03:50,933 [torchrl][INFO] Max num steps: 194, rb length 7700\n",
      "2024-04-17 21:03:50,957 [torchrl][INFO] Max num steps: 194, rb length 7700\n",
      "2024-04-17 21:03:51,114 [torchrl][INFO] Max num steps: 194, rb length 7800\n",
      "2024-04-17 21:03:51,125 [torchrl][INFO] Max num steps: 194, rb length 7800\n",
      "2024-04-17 21:03:51,140 [torchrl][INFO] Max num steps: 194, rb length 7800\n",
      "2024-04-17 21:03:51,152 [torchrl][INFO] Max num steps: 194, rb length 7800\n",
      "2024-04-17 21:03:51,167 [torchrl][INFO] Max num steps: 194, rb length 7800\n",
      "2024-04-17 21:03:51,185 [torchrl][INFO] Max num steps: 194, rb length 7800\n",
      "2024-04-17 21:03:51,202 [torchrl][INFO] Max num steps: 194, rb length 7800\n",
      "2024-04-17 21:03:51,218 [torchrl][INFO] Max num steps: 194, rb length 7800\n",
      "2024-04-17 21:03:51,236 [torchrl][INFO] Max num steps: 194, rb length 7800\n",
      "2024-04-17 21:03:51,250 [torchrl][INFO] Max num steps: 194, rb length 7800\n",
      "2024-04-17 21:03:51,412 [torchrl][INFO] Max num steps: 194, rb length 7900\n",
      "2024-04-17 21:03:51,422 [torchrl][INFO] Max num steps: 194, rb length 7900\n",
      "2024-04-17 21:03:51,437 [torchrl][INFO] Max num steps: 194, rb length 7900\n",
      "2024-04-17 21:03:51,454 [torchrl][INFO] Max num steps: 194, rb length 7900\n",
      "2024-04-17 21:03:51,476 [torchrl][INFO] Max num steps: 194, rb length 7900\n",
      "2024-04-17 21:03:51,492 [torchrl][INFO] Max num steps: 194, rb length 7900\n",
      "2024-04-17 21:03:51,507 [torchrl][INFO] Max num steps: 194, rb length 7900\n",
      "2024-04-17 21:03:51,527 [torchrl][INFO] Max num steps: 194, rb length 7900\n",
      "2024-04-17 21:03:51,543 [torchrl][INFO] Max num steps: 194, rb length 7900\n",
      "2024-04-17 21:03:51,559 [torchrl][INFO] Max num steps: 194, rb length 7900\n",
      "2024-04-17 21:03:51,715 [torchrl][INFO] Max num steps: 210, rb length 8000\n",
      "2024-04-17 21:03:51,724 [torchrl][INFO] Max num steps: 210, rb length 8000\n",
      "2024-04-17 21:03:51,739 [torchrl][INFO] Max num steps: 210, rb length 8000\n",
      "2024-04-17 21:03:51,752 [torchrl][INFO] Max num steps: 210, rb length 8000\n",
      "2024-04-17 21:03:51,767 [torchrl][INFO] Max num steps: 210, rb length 8000\n",
      "2024-04-17 21:03:51,781 [torchrl][INFO] Max num steps: 210, rb length 8000\n",
      "2024-04-17 21:03:51,798 [torchrl][INFO] Max num steps: 210, rb length 8000\n",
      "2024-04-17 21:03:51,815 [torchrl][INFO] Max num steps: 210, rb length 8000\n",
      "2024-04-17 21:03:51,831 [torchrl][INFO] Max num steps: 210, rb length 8000\n",
      "2024-04-17 21:03:51,846 [torchrl][INFO] Max num steps: 210, rb length 8000\n",
      "2024-04-17 21:03:51,849 [torchrl][INFO] solved after 30000 steps, 1270 episodes and in 16.094929218292236s.\n"
     ]
    }
   ],
   "source": [
    "from torchrl.modules import EGreedyModule, MLP, QValueModule\n",
    "\n",
    "value_mlp = MLP(out_features=env.action_spec.shape[-1], num_cells=[64, 64])\n",
    "value_net = Mod(value_mlp, in_keys=[\"observation\"], out_keys=[\"action_value\"])\n",
    "policy = Seq(value_net, QValueModule(env.action_spec))\n",
    "exploration_module = EGreedyModule(\n",
    "    env.action_spec, annealing_num_steps=100_000, eps_init=0.5\n",
    ")\n",
    "policy_explore = Seq(policy, exploration_module)\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data import LazyTensorStorage, ReplayBuffer\n",
    "\n",
    "init_rand_steps = 5000\n",
    "frames_per_batch = 100\n",
    "optim_steps = 10\n",
    "collector = SyncDataCollector(\n",
    "    env,\n",
    "    policy,\n",
    "    frames_per_batch=frames_per_batch,\n",
    "    total_frames=-1,\n",
    "    init_random_frames=init_rand_steps,\n",
    ")\n",
    "rb = ReplayBuffer(storage=LazyTensorStorage(100_000))\n",
    "\n",
    "from torchrl.objectives import DQNLoss, SoftUpdate\n",
    "from torch.optim import Adam\n",
    "\n",
    "loss = DQNLoss(value_network=policy, action_space=env.action_spec, delay_value=True)\n",
    "optim = Adam(loss.parameters(), lr=0.02)\n",
    "updater = SoftUpdate(loss, eps=0.99)\n",
    "\n",
    "from torchrl._utils import logger as torchrl_logger\n",
    "from torchrl.record import CSVLogger, VideoRecorder\n",
    "\n",
    "path = \".logs/training_loop\"\n",
    "logger = CSVLogger(exp_name=\"dqn\", log_dir=path, video_format=\"mp4\")\n",
    "video_recorder = VideoRecorder(logger, tag=\"video\")\n",
    "record_env = TransformedEnv(\n",
    "    GymEnv(\"CartPole-v1\", from_pixels=True, pixels_only=False), video_recorder\n",
    ")\n",
    "\n",
    "total_count = 0\n",
    "total_episodes = 0\n",
    "t0 = time.time()\n",
    "for i, data in enumerate(collector):\n",
    "    # Write data in replay buffer\n",
    "    rb.extend(data)\n",
    "    max_length = rb[:][\"next\", \"step_count\"].max()\n",
    "    if len(rb) > init_rand_steps:\n",
    "        # Optim loop (we do several optim steps\n",
    "        # per batch collected for efficiency)\n",
    "        for _ in range(optim_steps):\n",
    "            sample = rb.sample(128)\n",
    "            loss_vals = loss(sample)\n",
    "            loss_vals[\"loss\"].backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            # Update exploration factor\n",
    "            exploration_module.step(data.numel())\n",
    "            # Update target params\n",
    "            updater.step()\n",
    "            if i % 10:\n",
    "                torchrl_logger.info(f\"Max num steps: {max_length}, rb length {len(rb)}\")\n",
    "            total_count += data.numel()\n",
    "            total_episodes += data[\"next\", \"done\"].sum()\n",
    "    if max_length > 200:\n",
    "        break\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "torchrl_logger.info(\n",
    "    f\"solved after {total_count} steps, {total_episodes} episodes and in {t1-t0}s.\"\n",
    ")\n",
    "\n",
    "record_env.rollout(max_steps=1000, policy=policy)\n",
    "video_recorder.dump()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
